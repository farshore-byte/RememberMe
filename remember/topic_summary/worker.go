package topic_summary

import (
	"context"
	"fmt"
	"log"
	"time"

	"github.com/openai/openai-go/v2"
	"github.com/openai/openai-go/v2/option"
)

// Worker æ¶ˆè´¹é˜Ÿåˆ—æ¶ˆæ¯
type Worker struct {
	Queue        *QueueClient
	StopCh       chan struct{}
	PollInterval time.Duration
	DBClient     *TopicClient
	Template     *TopicTemplat
}

// NewWorker åˆ›å»º Worker
func NewWorker(interval time.Duration) *Worker {
	return &Worker{
		Queue:        MessageQueue,
		StopCh:       make(chan struct{}),
		PollInterval: interval,
		DBClient:     DBClient, // å…¨å±€ DBClient
		Template:     NewTopicSummaryTemplate(),
	}
}

// Start å¯åŠ¨ Worker
func (w *Worker) Start() {
	go func() {
		for {
			select {
			case <-w.StopCh:
				fmt.Println("Worker stopped")
				return
			default:
				w.processNext()
				time.Sleep(w.PollInterval)
			}
		}
	}()
}

// Stop åœæ­¢ Worker
func (w *Worker) Stop() {
	close(w.StopCh)
}

// processNext å¤„ç†é˜Ÿåˆ—ä¸­çš„ä¸‹ä¸€æ¡æ¶ˆæ¯
func (w *Worker) processNext() {
	ctx := context.Background()
	msg, err := w.Queue.Dequeue(ctx)
	if err != nil {
		if err.Error() != "redis: nil" { // é˜Ÿåˆ—ä¸ºç©º
			log.Printf("Error dequeue message: %v\n", err)
		}
		return
	}

	log.Printf("Processing session_id=%s, task_id=%s, retry=%d", msg.SessionID, msg.TaskID, msg.Retry)

	if err := w.processTopicSummary(msg); err != nil {
		log.Printf("âŒ Task failed, session_id=%s, task_id=%s, retry=%d, err=%v", msg.SessionID, msg.TaskID, msg.Retry, err)

		// åˆ¤æ–­æ˜¯å¦éœ€è¦é‡è¯•
		if msg.Retry < MaxRetry {
			msg.Retry++
			if _, enqueueErr := w.Queue.Enqueue(ctx, *msg); enqueueErr != nil {
				log.Printf("âŒ Re-enqueue failed, task_id=%s, err=%v", msg.TaskID, enqueueErr)
			} else {
				log.Printf("ğŸ” Task re-enqueued, session_id=%s, task_id=%s, retry=%d", msg.SessionID, msg.TaskID, msg.Retry)
			}
		} else {
			// è¶…è¿‡é‡è¯•æ¬¡æ•°ï¼Œå‘é€é£ä¹¦æŠ¥è­¦
			alertText := fmt.Sprintf(
				"*Topic summary task failed after %d retries!*\nTaskID: %s\nSessionID: %s\nLastError: %v",
				MaxRetry, msg.TaskID, msg.SessionID, err,
			)
			go SendFeishuMsgAsync(alertText)

			log.Printf("âš ï¸ Task dropped after %d retries, task_id=%s, last error: %v", MaxRetry, msg.TaskID, err)
		}
	}
}

// processTopicSummary å¤„ç†è¯é¢˜æ‘˜è¦é€»è¾‘
func (w *Worker) processTopicSummary(msg *QueueMessage) error {
	// 1. æ¶ˆæ¯è½¬æ–‡æœ¬
	messagesStr := MessagesToText(msg.Messages)

	// 2. æ„é€ ç³»ç»Ÿæç¤ºè¯
	dynamicVars := map[string]string{
		"messages_str": messagesStr,
	}
	systemPrompt, err := w.Template.BuildPrompt(dynamicVars)
	if err != nil {
		return fmt.Errorf("%s ç”Ÿæˆç³»ç»Ÿæç¤ºè¯å¤±è´¥: %w", SERVER_NAME, err)
	}

	// 3. æ‰§è¡Œæ¨¡å‹
	req := &ExecuteRequest{
		SystemPrompt: systemPrompt,
		Query:        User_query,
		Model:        Config.LLM.ModelID,
		Client:       &OpenAIClient,
	}
	result, err := Execute(req)
	if err != nil {
		return fmt.Errorf("%s æ‰§è¡Œæ¨¡å‹å¤±è´¥: %w", SERVER_NAME, err)
	}

	log.Printf("âœ… ç”Ÿæˆè¯é¢˜æ‘˜è¦æˆåŠŸ, task_id=%s", msg.TaskID)
	if len(result.JSON) == 0 {
		log.Printf("%s task_id=%s è¯é¢˜æ‘˜è¦ä¸ºç©º, è·³è¿‡ä¸Šä¼ ", SERVER_NAME, msg.TaskID)
		return nil
	}

	// 4. ä¸Šä¼ åˆ°æ•°æ®åº“
	if err := w.DBClient.UploadTopicSummary(context.Background(), msg, result.JSON); err != nil {
		return fmt.Errorf("%s ä¸Šä¼ è¯é¢˜æ‘˜è¦å¤±è´¥: %w", SERVER_NAME, err)
	}

	log.Printf("âœ… ä¸Šä¼ è¯é¢˜æ‘˜è¦æˆåŠŸ, session_id=%s, task_id=%s, topics_count=%d",
		msg.SessionID, msg.TaskID, len(result.JSON))
	return nil
}

// åˆå§‹åŒ– OpenAI å®¢æˆ·ç«¯
var OpenAIClient openai.Client

func init() {
	InitLLM()
}

// InitLLM åˆå§‹åŒ– OpenAI Client
func InitLLM() {
	OpenAIClient = openai.NewClient(
		option.WithAPIKey(Config.LLM.APIKey),
		option.WithBaseURL(Config.LLM.BaseURL),
	)
}
